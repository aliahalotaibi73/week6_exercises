{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliahalotaibi73/week6_exercises/blob/main/Motion_Detection_Practice_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PlMTEr58NK4"
      },
      "source": [
        "# Motion Detection Practice Exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYXqZrIA8NK5"
      },
      "source": [
        "In this exercise, you will implement a motion detection system using OpenCV. Your task is to detect and track moving objects in a video file. The goal is to identify areas of motion and process each frame accordingly. The video for this exercise can be found under `Example_Motion.mp4`.\n",
        "\n",
        "## Objectives\n",
        "- Load and process a video using OpenCV.\n",
        "- Create and utilize a background subtractor for motion detection.\n",
        "- Apply the background subtractor to each video frame to identify areas of motion.\n",
        "- Use OpenCV to manipulate and save the processed video.\n",
        "- Track and highlight moving objects in each frame.\n",
        "- Save the processed video with the detected motion areas.\n",
        "\n",
        "This exercise is designed to help you understand the fundamentals of motion detection and background subtraction in video processing. By the end of this exercise, you should be able to implement a basic motion detection pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPBmynwKAEFI"
      },
      "source": [
        "## Importing Required Libraries\n",
        "\n",
        "In this step, we'll import the essential libraries for processing video and performing motion detection.\n",
        "Make sure you have `opencv-python` installed in your environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "T2ZnPyzWABEm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP4lPP0CAII2"
      },
      "source": [
        "## Setting Up Video Capture\n",
        "In this section, you'll set up video capture using OpenCV's `cv2.VideoCapture()` to read the input video file. This is where you initialize the video stream that you'll process frame by frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "u2RzvIskAJQk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3866fc3d-2d10-4496-9658-29b9b18578fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "cap = cv2.VideoCapture('/content/Example_Motion.mp4')\n",
        "print(cap.isOpened())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfA_qKOQALCO"
      },
      "source": [
        "## Defining the Video Writer to Save the Output\n",
        "Here, you'll define the video writer's object `cv2.VideoWriter()`, which will be used to save the processed video with the motion detection applied."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "q8EiQzIzAL5Q"
      },
      "outputs": [],
      "source": [
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('motion_output.mp4', fourcc, 20.0, (600, 500))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbXLQKwqAMCx"
      },
      "source": [
        "## Creating the Background Subtractor\n",
        "\n",
        "Motion detection in videos often involves background subtraction.\n",
        "In this step, we'll create a background subtractor object using OpenCV's `createBackgroundSubtractorMOG2` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "COA6F4V5AOIY"
      },
      "outputs": [],
      "source": [
        "fgbg = cv2.createBackgroundSubtractorMOG2(detectShadows=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq3f47FcAQhR"
      },
      "source": [
        "## Processing the Video Frame by Frame\n",
        "\n",
        "Now, we'll loop through each frame of the video, apply the background subtractor to detect motion,\n",
        "and then write the processed frame to the output video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Kj6BR2cMARus"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "    # Capture each frame of the video\n",
        "    success, img = cap.read()\n",
        "\n",
        "    # Check if the frame is captured successfully\n",
        "    if success:\n",
        "        # Resize the frame for consistency\n",
        "        img = cv2.resize(img, (600, 500))\n",
        "\n",
        "        # Apply the background subtractor to detect moving objects\n",
        "        fgmask = fgbg.apply(img)\n",
        "\n",
        "        # Create a binary thresholded image for better motion detection\n",
        "        _, thresh = cv2.threshold(fgmask.copy(), 180, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        # Define a kernel for morphological operations\n",
        "        kernel = np.ones((7, 7), np.uint8)\n",
        "\n",
        "        # Apply erosion to remove noise from the thresholded image\n",
        "        thresh = cv2.erode(thresh, kernel)\n",
        "\n",
        "        # Apply dilation to strengthen the detected moving objects\n",
        "        thresh = cv2.dilate(thresh, None, iterations=6)\n",
        "\n",
        "        # Find contours of the detected motion\n",
        "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        # Draw rectangles around detected motion\n",
        "        for contour in contours:\n",
        "            # Calculate the area of the contour\n",
        "            area = cv2.contourArea(contour)\n",
        "\n",
        "            # Only consider significant motion (area > 1200)\n",
        "            if area > 1200:\n",
        "                # Get the bounding box coordinates for the motion\n",
        "                x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "                # Draw a rectangle around the detected motion and label it\n",
        "                cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 255), 3)\n",
        "                cv2.putText(img, 'MOTION DETECTED', (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "                # Write the processed frame with motion detection to the output video\n",
        "                out.write(img)\n",
        "\n",
        "    else:\n",
        "        # Break the loop if no more frames are available\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# while True:\n",
        "#   success, img = cap.read()\n",
        "#   if not success:\n",
        "#     break\n",
        "\n",
        "#     img = cv2.resize(img, (600, 500))\n",
        "#     fgmask = fgbg.apply(img)\n",
        "#     _, thresh = cv2.threshold(fgmask, 180, 255,cv2.THRESH_BINARY)\n",
        "#      thresh = cv2.dilate(cv2.erode(thresh, np.ones((7, 7), np.uint8)), None, iterations=6)\n",
        "\n",
        "#       contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "#       for contour in contours:\n",
        "#         if cv2.contourArea(contour) > 1200:\n",
        "#           x, y, w, h = cv2.boundingRect(contour)\n",
        "#           cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0,255), 3)\n",
        "#           cv2.putText(img, 'MOTION DETECTED', (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2) out.write(img)"
      ],
      "metadata": {
        "id": "QAComZwD2QdQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7gJInLkAUdi"
      },
      "source": [
        "## Releasing Resources\n",
        "\n",
        "Once all frames are processed, it's important to release the video capture and writer objects to free up system resources."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Resource Management: The release() methods are used to properly close and free up resources allocated by OpenCV for video capture and writing.\n",
        "Window Management: cv2.destroyAllWindows() closes any display windows, ensuring a clean exit without hanging or leaving unwanted windows open."
      ],
      "metadata": {
        "id": "53d0KW_06zyo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "lL8r4LYbAVfq"
      },
      "outputs": [],
      "source": [
        "# Release the video capture and writer objects\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "# Close all OpenCV windows\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}