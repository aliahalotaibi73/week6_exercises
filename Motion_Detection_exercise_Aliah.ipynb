{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliahalotaibi73/week6_exercises/blob/main/Motion_Detection_exercise_Aliah.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46d59385",
      "metadata": {
        "id": "46d59385"
      },
      "source": [
        "# Motion Detection Using Background Subtraction in OpenCV"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "335d2d74",
      "metadata": {
        "id": "335d2d74"
      },
      "source": [
        "### Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3356d8ce",
      "metadata": {
        "id": "3356d8ce"
      },
      "source": [
        "In this tutorial, we will learn how to perform **motion detection** using background subtraction in OpenCV. Background subtraction is a technique where we analyze the difference between the current frame and a background model to detect objects that have moved in the scene."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67af2516",
      "metadata": {
        "id": "67af2516"
      },
      "source": [
        "### Step 1: Importing Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1cdb727e",
      "metadata": {
        "id": "1cdb727e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "898c5ff0",
      "metadata": {
        "id": "898c5ff0"
      },
      "source": [
        "### Step 2: Setting Up Video Capture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a319eab8",
      "metadata": {
        "id": "a319eab8",
        "outputId": "e7da6e81-da46-49ff-9103-f555ff83461b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "\n",
        "cap = cv2.VideoCapture('/content/Motion_Detection_Test.mp4')\n",
        "print(cap.isOpened())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c3223db",
      "metadata": {
        "id": "2c3223db"
      },
      "source": [
        "Here, we initialize the video capture object by loading a video file (`Motion_Detection_Test.mp4`). This object allows us to read frames from the video in a loop."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01c1af2a",
      "metadata": {
        "id": "01c1af2a"
      },
      "source": [
        "### Step 3: Defining the Video Writer to Save the Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e937089f",
      "metadata": {
        "id": "e937089f"
      },
      "outputs": [],
      "source": [
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('motion_output.mp4', fourcc, 20.0, (600, 500))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80216f4f",
      "metadata": {
        "id": "80216f4f"
      },
      "source": [
        "In this step, we create a `VideoWriter` object to save the processed frames with motion detection. The codec is set to `'mp4v'`, and the output file is `motion_output.mp4`. The resolution is `(600x500)` with a frame rate of `20.0`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92589154",
      "metadata": {
        "id": "92589154"
      },
      "source": [
        "### Step 4: Creating the Background Subtractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f1945807",
      "metadata": {
        "id": "f1945807"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create a background subtractor using MOG2\n",
        "fgbg = cv2.createBackgroundSubtractorMOG2(detectShadows=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb2b9d5d",
      "metadata": {
        "id": "fb2b9d5d"
      },
      "source": [
        "We use the MOG2 background subtractor provided by OpenCV. This method detects moving objects by subtracting the background. The `detectShadows=True` option helps distinguish moving objects from their shadows, improving accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c5f8f16",
      "metadata": {
        "id": "5c5f8f16"
      },
      "source": [
        "### Step 5: Processing the Video Frame by Frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8fc29336",
      "metadata": {
        "id": "8fc29336"
      },
      "outputs": [],
      "source": [
        "\n",
        "while True:\n",
        "    # Capture each frame of the video\n",
        "    success, img = cap.read()\n",
        "\n",
        "    # Check if the frame is captured successfully\n",
        "    if success:\n",
        "        # Resize the frame for consistency\n",
        "        img = cv2.resize(img, (600, 500))\n",
        "\n",
        "        # Apply the background subtractor to detect moving objects\n",
        "        fgmask = fgbg.apply(img)\n",
        "\n",
        "        # Create a binary thresholded image for better motion detection\n",
        "        _, thresh = cv2.threshold(fgmask.copy(), 180, 255, cv2.THRESH_BINARY) # less than 180 will be black and above will be wight\n",
        "\n",
        "        # Define a kernel for morphological operations, kernel means filters\n",
        "        kernel = np.ones((7, 7), np.uint8)\n",
        "\n",
        "        # Apply erosion to remove noise from the thresholded image\n",
        "        thresh = cv2.erode(thresh, kernel)\n",
        "\n",
        "        # Apply dilation to strengthen the detected moving objects\n",
        "        thresh = cv2.dilate(thresh, None, iterations=6)\n",
        "\n",
        "        # Find contours of the detected motion\n",
        "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # شكل الكنتور لازم يكون انسيابي وناعم بدون ذبذبات\n",
        "\n",
        "        # Draw rectangles around detected motion\n",
        "        for contour in contours:\n",
        "            # Calculate the area of the contour\n",
        "            area = cv2.contourArea(contour)\n",
        "\n",
        "            # Only consider significant motion (area > 1200)\n",
        "            if area > 1200:\n",
        "                # Get the bounding box coordinates for the motion\n",
        "                x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "                # Draw a rectangle around the detected motion and label it\n",
        "                cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 255), 3) # dry rectangle\n",
        "                cv2.putText(img, 'MOTION DETECTED', (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "        # Write the processed frame with motion detection to the output video\n",
        "                out.write(img)\n",
        "\n",
        "    else:\n",
        "        # Break the loop if no more frames are available\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e03b1b5",
      "metadata": {
        "id": "1e03b1b5"
      },
      "source": [
        "In this step, we continuously capture frames from the video, apply the background subtractor, and use contour detection to identify significant motion. Rectangles are drawn around detected motion, and each frame is saved to the output video."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b1a1418",
      "metadata": {
        "id": "4b1a1418"
      },
      "source": [
        "### Step 6: Releasing Resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "39a5cc50",
      "metadata": {
        "id": "39a5cc50"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Release the video capture and writer objects\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "# Close all OpenCV windows\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c9d2aec",
      "metadata": {
        "id": "6c9d2aec"
      },
      "source": [
        "After processing all the frames, we release the resources by closing the video capture and writer objects. All OpenCV windows are also closed.\n",
        "[Source](https://github.com/zain18jan2000/Motion-Detection-Using-BackgroundSubtractorMOG2/tree/main) for this tutorial."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}